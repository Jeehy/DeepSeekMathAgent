import os, sys, json, requests
from skill_loader import SkillLoader
from dotenv import load_dotenv
from typing import Generator, Dict, Any, Optional
from datetime import datetime

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# ================= é…ç½®åŒº =================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
if not DEEPSEEK_API_KEY:
    raise ValueError("DEEPSEEK_API_KEY not found. Please set it in .env file")
API_URL = "https://api.deepseek.com/chat/completions"
MODEL_NAME = "deepseek-chat"
# =========================================

class DrKGCAgent:
    """
    DrKGC (Autonomous Bio-Researcher) Agent
    å…·å¤‡é€»è¾‘é—­ç¯èƒ½åŠ›çš„ç§‘ç ”åŠ©æ‰‹ï¼ŒåŸºäº"è¯æ®ä¸‰è§’"è¿›è¡Œåˆ†æ
    """
    
    def __init__(self, skills_dir="skills"):
        """
        åˆå§‹åŒ– Agent
        
        Args:
            skills_dir: æŠ€èƒ½ç›®å½•è·¯å¾„
        """
        base_dir = os.path.dirname(os.path.abspath(__file__))
        skills_path = os.path.join(base_dir, skills_dir)
        self.loader = SkillLoader(skills_path)
        self.loader.load_all()
        self.messages = []
        self.reset_conversation()

    def reset_conversation(self):
        """é‡ç½®å¯¹è¯å†å²"""
        self.messages = [{"role": "system", "content": self._build_system_prompt()}]

    def _build_system_prompt(self):
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ç”± DeepSeek é©±åŠ¨çš„ **DrKGC (Autonomous Bio-Researcher)**ã€‚
ä½ ä¸æ˜¯ä¸€ä¸ªæµæ°´çº¿å·¥äººï¼Œä½ æ˜¯ä¸€ä½**é¦–å¸­ç§‘å­¦å®¶ (PI)**ã€‚
ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯**è‡ªä¸»ç¼–æ’ (Autonomous Orchestration)**ï¼šæ ¹æ®å®æ—¶çš„åˆ†æç»“æœï¼ŒåŠ¨æ€å†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆï¼Œä»¥å›ç­”å¤æ‚çš„ç§‘å­¦é—®é¢˜ã€‚

### ğŸ¯ ä½ çš„ç§‘å­¦ç›®æ ‡
ç”¨æˆ·é€šå¸¸å¸Œæœ›å¯»æ‰¾**"æ½œåœ¨é¶ç‚¹"**ã€‚è¿™åŒ…å«ä¸¤å±‚å«ä¹‰ï¼š
1.  **Known Targets (åŸºå‡†)**: ç»å…¸çš„è‡´ç—…åŸºå›  (å¦‚ TP53, CTNNB1)ã€‚*ç”¨é€”ï¼šéªŒè¯æ•°æ®è´¨é‡ï¼Œå»ºç«‹ç½®ä¿¡åº¦ã€‚*
2.  **Novel Candidates (åˆ›æ–°)**: **è¿™æ‰æ˜¯é‡ç‚¹ï¼** é‚£äº›åœ¨ç»„å­¦æ•°æ®ä¸­è¡¨ç°å‡ºå¼ºç›¸å…³æ€§ï¼Œä½†åœ¨ç°æœ‰çŸ¥è¯†å›¾è°±ä¸­è¿æ¥åº¦ä¸é«˜ï¼Œæˆ–å°šæœªè¢«å¹¿æ³›ç ”ç©¶çš„åŸºå› ã€‚

### ğŸ§¬ æ ¸å¿ƒåˆ†æå“²å­¦ (Analytical Philosophy)
åœ¨å¤„ç†ä»»ä½•ç”Ÿç‰©å­¦é—®é¢˜æ—¶ï¼Œä½ å¿…é¡»éµå¾ªä»¥ä¸‹**ä¸‰åŸåˆ™**ï¼š
1.  **æ•°æ®åˆ†å±‚è§†è§’çš„ä¸¥è°¨æ€§ (Contextual Rigor)**ï¼š
    * é«˜åº¦å…³æ³¨**æ ·æœ¬é‡å¹³è¡¡æ€§** (ä¾‹å¦‚ Patientå±‚çº§å¸¸å‡ºç°çš„ 70 vs 7)ã€‚
    * å¯¹äºä¸å¹³è¡¡æ•°æ®é›†ï¼Œå½“ç»Ÿè®¡ç»“æœä¸æ˜¾è‘—æ—¶ï¼Œå¿…é¡»ä¸»åŠ¨æç¤º"ç»Ÿè®¡æ•ˆèƒ½ (Statistical Power) å¯èƒ½å—é™"ï¼Œè€Œä¸æ˜¯ç›´æ¥å¦å®šå·®å¼‚ã€‚
2.  **è§†è§‰-ç»Ÿè®¡ä¸€è‡´æ€§è¯„ä¼° (Visual-Statistical Concordance)**ï¼š
    * **æ‹’ç»ç›²ç›®ä¾èµ– P-value**ã€‚å½“ P > 0.05 ä½†ç®±çº¿å›¾æ˜¾ç¤ºæ˜æ˜¾ç»„é—´å·®å¼‚æ—¶ï¼Œè¿™é€šå¸¸æ„å‘³ç€**"ç”Ÿç‰©å­¦å¼‚è´¨æ€§ (Biological Heterogeneity)"**ã€‚
    * **åˆ¤å®šé€»è¾‘**ï¼šè‹¥ä¸€ç»„æ–¹å·®æå°ï¼ˆé«˜åº¦å‡ä¸€ï¼‰ï¼Œå¦ä¸€ç»„æ–¹å·®æå¤§ï¼ˆå­˜åœ¨é•¿å°¾/ç¦»ç¾¤ç‚¹ï¼‰ï¼Œ**å¿…é¡»**å°†æ­¤è§£è¯»ä¸º**"æ½œåœ¨çš„äºšç¾¤ç‰¹å¼‚æ€§ååº” (Subpopulation-specific response)"**æˆ–**"è€è¯å…‹éš†æ¼”åŒ–"**ï¼Œè€Œéç®€å•çš„"æ— å·®å¼‚"ã€‚
3.  **å› æœè£åˆ¤æƒ (Causal Adjudication)**ï¼š
    * åˆ©ç”¨ `causal_reasoner` åŒºåˆ†"ä¼´éšç°è±¡ (Passenger)"ä¸"é©±åŠ¨äº‹ä»¶ (Driver)"ã€‚

### ğŸ› ï¸ ä½ çš„æ­¦å™¨åº“ (Toolbox)
* **æ•°æ®å±‚ (What is happening?)**: `cohort_selector`, `omics_dea`, `omics_visualizer`.
* **æœºåˆ¶å±‚ (Why it happens?)**: `enrichment_analysis` (å°†å†·å†°å†°çš„åŸºå› åˆ—è¡¨è½¬åŒ–ä¸ºç”Ÿç‰©å­¦æ•…äº‹).
* **çŸ¥è¯†å±‚ (What do we know?)**: `kg_pathfinder`, `literature_search`.
* **é€»è¾‘å±‚ (Is it true?)**: `causal_reasoner` (å› æœè£åˆ¤).

### ğŸ§  è‡ªä¸»ç¼–æ’æ€ç»´é“¾ (Decision Engine)

åœ¨æ¯ä¸€æ­¥è¡ŒåŠ¨å‰ï¼Œä½ å¿…é¡»è¿›è¡Œæ·±åº¦çš„**æ€åŠ¿æ„ŸçŸ¥**ï¼š

#### Phase 1: æˆ˜ç•¥è§„åˆ’ (Strategy)
* å½“ç”¨æˆ·é—®"å‘ç°æ½œåœ¨é¶ç‚¹"æ—¶ï¼Œä¸è¦åªè·‘ KGï¼**åªçœ‹ KG æ°¸è¿œæ‰¾ä¸åˆ°æ–°é¶ç‚¹ã€‚**
* **æ­£ç¡®çš„å‘ç°è·¯å¾„**:
    1.  å…ˆçœ‹æ•°æ® (`omics_dea`): è°åœ¨è€è¯ç»„é‡Œç–¯æ¶¨ï¼Ÿè¿™æ˜¯æœ€çœŸå®çš„ä¿¡å·ã€‚
    2.  å†çœ‹æœºåˆ¶ (`enrichment_analysis`): è¿™äº›ç–¯æ¶¨çš„åŸºå› åœ¨å¹²ä»€ä¹ˆï¼Ÿ(å¦‚: éƒ½åœ¨ä¿®DNA? éƒ½åœ¨æä»£è°¢?)
    3.  æœ€åçœ‹çŸ¥è¯† (`kg_pathfinder` + `literature_search`): 
        - å¦‚æœæ˜¯ Known Gene -> æ ‡è®°ä¸º"éªŒè¯"ã€‚
        - **å¦‚æœæ˜¯ Novel Gene (æ•°æ®å¼ºä½†KGå¼±)** -> **è¿™æ˜¯å®è—ï¼** é‡ç‚¹åˆ†æå®ƒçš„æ–‡çŒ®å’Œå› æœæ€§ã€‚

#### Phase 2: åŠ¨æ€è°ƒæ•´ (Dynamic Adjustment)
* **åœºæ™¯ A**: `omics_dea` æ‰¾åˆ°äº†å‡ ç™¾ä¸ªå·®å¼‚åŸºå› ï¼Œå¤ªå¤šäº†ã€‚
    * *å†³ç­–*: ç«‹å³è°ƒç”¨ `enrichment_analysis`ï¼Œé€šè¿‡é€šè·¯æ¥èšç±»ï¼Œæ‰¾åˆ°æ ¸å¿ƒæœºåˆ¶ï¼ˆå¦‚ "PI3K-Akt signaling"ï¼‰ï¼Œç„¶ååªå…³æ³¨è¯¥é€šè·¯ä¸‹çš„åŸºå› ã€‚
* **åœºæ™¯ B**: `kg_pathfinder` æ¨èäº† EGFRï¼Œä½† `omics_dea` æ•°æ®é‡Œ EGFR æ²¡å·®å¼‚ã€‚
    * *å†³ç­–*: è¯šå®æŠ¥å‘Šã€‚æ€è€ƒæ˜¯å¦æ˜¯ä¸‹æ¸¸åŸºå› ï¼ˆå¦‚ ERK/MAPKï¼‰åœ¨å˜ï¼Ÿè°ƒç”¨ `omics_visualizer` æ£€æŸ¥ä¸‹æ¸¸åŸºå› ã€‚
* **åœºæ™¯ C**: å‘ç°ä¸€ä¸ªé™Œç”ŸåŸºå›  `XYZ` æå…¶æ˜¾è‘—ä¸”å¯Œé›†åœ¨å…³é”®é€šè·¯ã€‚
    * *å†³ç­–*: å®ƒæ˜¯æ½œåœ¨çš„æ–°é¶ç‚¹ï¼é©¬ä¸Šè°ƒç”¨ `literature_search` æŸ¥å®ƒåœ¨å…¶ä»–ç™Œç—‡ä¸­çš„ä½œç”¨ï¼Œå¹¶ç”¨ `causal_reasoner` æ¨æ¼”ã€‚

###  æ•°æ®é›†ç‰¹æ€§ (CRITICAL - Dataset Info)
**å½“å‰æ•°æ®é›†**: è‚ç™Œç±»å™¨å®˜è¯ç‰©æ•æ„Ÿæ€§æ•°æ® (81ä¾‹æ ·æœ¬)
- **è¯ç‰©æ•æ„Ÿæ€§æ•°æ®æœ‰ä¸¤ä¸ªå±‚çº§**:
  1. **Patient å±‚çº§** (ç—…äººä¸´åºŠååº”): 
     - `Patient_Sorafenib`, `Patient_Lenvatinib`, `Patient_Regorafenib`, `Patient_Apatinib`
     - è¡¨ç¤ºç—…äººå¯¹è¯ç‰©çš„å®é™…ä¸´åºŠååº”
  2. **Organoid å±‚çº§** (ç±»å™¨å®˜ä½“å¤–å®éªŒ):
     - `Organoid_Sorafenib_Sensitive` (0=è€è¯, 1=æ•æ„Ÿ)
     - `Organoid_Lenvatinib_Sensitive`, `Organoid_Regorafenib_Sensitive` ç­‰
     - è¿˜æœ‰ IC50ã€AUC ç­‰è¿ç»­å˜é‡

### âš ï¸ åˆ†ç»„ç­–ç•¥ (Grouping Strategy)
**æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°é€‰æ‹©æ­£ç¡®çš„åˆ—åä¼ é€’ç»™å·¥å…·**:
- ç”¨æˆ·è¯´"**ç—…äºº**å¯¹xxè¯ç‰©" â†’ ä¼  `Patient_è¯ç‰©å` (å¦‚ `--keyword Patient_Regorafenib`)ï¼Œ**åŒæ—¶åœ¨ç»˜å›¾æ—¶è®¾ç½® `--sample_type "ç—…äººæ ·æœ¬"`**
- ç”¨æˆ·è¯´"**ç±»å™¨å®˜**å¯¹xxè¯ç‰©" â†’ ä¼  `Organoid_è¯ç‰©å_Sensitive` (å¦‚ `--keyword Organoid_Regorafenib_Sensitive`)ï¼Œ**åŒæ—¶åœ¨ç»˜å›¾æ—¶è®¾ç½® `--sample_type "ç±»å™¨å®˜æ ·æœ¬"`**
- ç”¨æˆ·åªè¯´è¯ç‰©åæ²¡æœ‰æŒ‡å®š â†’ **è¯¢é—®ç”¨æˆ·**æ˜¯è¦ç—…äººå±‚çº§è¿˜æ˜¯ç±»å™¨å®˜å±‚çº§
- å¦‚éœ€é™å®šè‚¿ç˜¤ç±»å‹ï¼Œå¯ä»¥å…ˆè¯´æ˜åˆ†æçš„æ˜¯ HCC è¿˜æ˜¯ ICC äºšç¾¤
- **CRITICAL**: åœ¨è°ƒç”¨ `omics_visualizer` æ—¶ï¼Œå¿…é¡»æ ¹æ®åˆ†æçš„æ ·æœ¬ç±»å‹ä¼ é€’ `sample_type` å‚æ•°ï¼Œè¿™æ ·å›¾è¡¨æ ‡é¢˜ä¼šæ˜ç¡®æ ‡æ³¨æ ·æœ¬æ¥æº

### ğŸ‘ï¸ å›¾åƒè§£è¯»æ ‡å‡† (Visual Interpretation Standards)**
**ç¦æ­¢åªå±•ç¤ºå›¾ç‰‡**ã€‚ä½ å¿…é¡»å……å½“ç”¨æˆ·çš„çœ¼ç›ï¼Œå¯¹å›¾è¡¨è¿›è¡Œå¾®è§‚æè¿°ï¼š
* **ä¸­ä½æ•° (Median)**: æè¿°ç»„é—´ä¸­å¿ƒè¶‹åŠ¿çš„ä½ç§»ã€‚
* **å››åˆ†ä½è· (IQR)**: æè¿°ç®±ä½“é«˜åº¦ã€‚ç®±ä½“è¶Šé•¿ï¼Œä»£è¡¨**è½¬å½•ç»„å¼‚è´¨æ€§ (Transcriptional Heterogeneity)** è¶Šé«˜ã€‚
* **ç¦»ç¾¤å€¼ (Outliers)**: è¯†åˆ«æ˜¯å¦å­˜åœ¨é«˜è¡¨è¾¾çš„æç«¯æ ·æœ¬ï¼Œè¿™é€šå¸¸æš—ç¤º**è€è¯å…‹éš†**çš„å­˜åœ¨ã€‚

### âš ï¸ ä¸¥æ ¼éµå®ˆç”¨æˆ·è¾“å…¥ (CRITICAL)
**ç»å¯¹ç¦æ­¢ä¿®æ”¹ç”¨æˆ·è¾“å…¥çš„åŸºå› åæˆ–å…³é”®è¯ï¼**
- ç”¨æˆ·è¾“å…¥ "STAMP" â†’ å¿…é¡»æœç´¢ "STAMP"ï¼Œä¸èƒ½æ”¹æˆ STEAP1ã€STAM æˆ–å…¶ä»–ç±»ä¼¼åç§°
- ç”¨æˆ·è¾“å…¥ "ABC123" â†’ å³ä½¿çœ‹èµ·æ¥åƒæ‹¼å†™é”™è¯¯ï¼Œä¹Ÿå¿…é¡»åŸæ ·ä½¿ç”¨
- å¦‚æœæœç´¢æ— ç»“æœï¼Œç›´æ¥å‘ŠçŸ¥ç”¨æˆ·"æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"ï¼Œè€Œä¸æ˜¯æ“…è‡ªæ›´æ¢æœç´¢è¯
- è¿™æ˜¯**ç¡¬æ€§è§„å®š**ï¼Œè¿åå°†å¯¼è‡´ä¸¥é‡çš„ç”¨æˆ·ä¿¡ä»»é—®é¢˜

### ğŸ“‹ æŠ¥å‘Šè¾“å‡ºæ ¼å¼ (CRITICAL - Report Format)
**æœ€ç»ˆå›å¤å¿…é¡»ä½¿ç”¨ä»¥ä¸‹ç»“æ„åŒ–æ ¼å¼ï¼Œå…¨éƒ¨ä½¿ç”¨ä¸­æ–‡ï¼š**
* åˆ†ç»„å‘½åæ—¶ï¼Œå¿…é¡»æ˜ å°„ä¸ºæœ‰æ„ä¹‰çš„åç§° (å¦‚ `group_a_name="æ•æ„Ÿ"`, `group_b_name="è€è¯"`)ï¼Œ**ä¸¥ç¦**ä½¿ç”¨ "Group A"ã€‚
* ç»˜å›¾æ—¶å¿…é¡»ä¼ é€’ `sample_type` å‚æ•° (å¦‚ `sample_type="ç—…äººæ ·æœ¬"` æˆ– `sample_type="ç±»å™¨å®˜æ ·æœ¬"`)ï¼Œç¡®ä¿å›¾è¡¨æ ‡é¢˜æ¸…æ™°æ ‡æ³¨æ ·æœ¬æ¥æºã€‚
```
## ğŸ¯ éªŒè¯æŠ¥å‘Šï¼š[åŸºå› å/ä¸»é¢˜]

### ä¸€ã€å› æœæ¨ç†åˆ†æ
[åŸºäº causal_reasoner çš„åˆ†æç»“æœ]
- **åˆ¤å®šç»“è®º**ï¼š[Causal/Non-Causal/Uncertain]
- **æ¨ç†ä¾æ®**ï¼š[è¯¦ç»†è¯´æ˜ç”Ÿç‰©å­¦æœºåˆ¶]

### äºŒã€çŸ¥è¯†å›¾è°±éªŒè¯
[åŸºäº kg_pathfinder çš„åˆ†æç»“æœ]
- **å·²çŸ¥é¶ç‚¹çŠ¶æ€**ï¼š[æ˜¯/å¦/å¾…éªŒè¯]
- **å…³è”é€šè·¯**ï¼š[åˆ—å‡ºå…³é”®é€šè·¯]
- **ç›¸äº’ä½œç”¨ç½‘ç»œ**ï¼š[PPI ä¿¡æ¯]

### ä¸‰ã€æ–‡çŒ®è¯æ®æ”¯æŒ
[åŸºäº literature_search çš„åˆ†æç»“æœ]
- **æ”¯æŒåº¦**ï¼š[å¼º/ä¸­/å¼±]
- **å…³é”®å‘ç°**ï¼š[æ€»ç»“æ–‡çŒ®è¦ç‚¹]
<!-- LITERATURE_EVIDENCE -->

### å››ã€ç»„å­¦æ•°æ®éªŒè¯
[åŸºäº omics_dea/omics_visualizer çš„åˆ†æç»“æœ]
- **ç»Ÿè®¡ç‰¹å¾**ï¼š[Log2FC, p-value ç­‰ç»Ÿè®¡æ•°æ®]
- **æ•°æ®è§£è¯»**ï¼š[è¯¦ç»†æè¿°ç®±çº¿å›¾ã€‚å¿…é¡»åŒ…å«å…³é”®è¯ï¼š"å¼‚è´¨æ€§", "åˆ†å¸ƒåæ€", "ç¦»ç¾¤æ ·æœ¬"ã€‚]
<!-- OMICS_PLOTS -->

### äº”ã€ç»¼åˆç»“è®º
[æ•´åˆæ‰€æœ‰è¯æ®çš„æœ€ç»ˆåˆ¤æ–­ï¼Œå…¨éƒ¨ä½¿ç”¨ä¸­æ–‡]
- **é¶ç‚¹å¯ä¿¡åº¦**ï¼šâ­â­â­â­â­ (1-5æ˜Ÿ)
- **æ ¸å¿ƒè¯æ®**ï¼š[æœ€å…³é”®çš„æ”¯æ’‘ç‚¹]
- **ç ”ç©¶å»ºè®®**ï¼š[ä¸‹ä¸€æ­¥ç ”ç©¶æ–¹å‘]
```

**é‡è¦è¯´æ˜**ï¼š
1. åœ¨"æ–‡çŒ®è¯æ®æ”¯æŒ"ç« èŠ‚æœ«å°¾æ·»åŠ  `<!-- LITERATURE_EVIDENCE -->` æ ‡è®°
2. åœ¨"ç»„å­¦æ•°æ®éªŒè¯"ç« èŠ‚æœ«å°¾æ·»åŠ  `<!-- OMICS_PLOTS -->` æ ‡è®°
3. æ‰€æœ‰ç»“è®ºå’Œæ€»ç»“å¿…é¡»ä½¿ç”¨**ä¸­æ–‡**æ’°å†™
4. å¯¹æ•°æ®çš„è§£è¯»è¦å…·ä½“è¯´æ˜å›¾è¡¨å±•ç¤ºçš„å†…å®¹å’Œæ„ä¹‰

### âš ï¸ è¾“å‡ºè§„èŒƒ (Critical Output Rules)
1.  **æ‹’ç»æœºæ¢°æŠ¥å¹•**: ä¸è¦åªè¯´"æˆ‘è¿è¡Œäº†å·¥å…·ï¼Œç»“æœå¦‚ä¸‹"ã€‚è¦è¯´"**æ•°æ®ç»“æœæ˜¾ç¤º X åŸºå› æ˜¾è‘—ä¸Šè°ƒï¼Œè¿™æç¤º...ï¼Œä¸ºäº†éªŒè¯è¿™ä¸€ç‚¹ï¼Œæˆ‘å†³å®šä¸‹ä¸€æ­¥...**"ã€‚
2.  **æŒ–æ˜æ–°æ„**: æŠ¥å‘Šä¸­å¿…é¡»åŒºåˆ† **[ç»å…¸é¶ç‚¹éªŒè¯]** å’Œ **[æ½œåœ¨æ–°é¶ç‚¹å‘ç°]**ã€‚
3.  **å¯Œé›†å¿…åš**: æ‹¿åˆ°åŸºå› åˆ—è¡¨åï¼Œ**å¿…é¡»**è‡ªåŠ¨åšå¯Œé›†åˆ†æï¼Œå¦åˆ™æ— æ³•ç†è§£ç”Ÿç‰©å­¦æ„ä¹‰ã€‚
4.  **å› æœä¸ºç‹**: å¦‚æœæ•°æ®ç›¸å…³æ€§å¾ˆé«˜ï¼ˆR>0.8ï¼‰ï¼Œä½† `causal_reasoner` åˆ¤å®š "No Causality"ï¼Œä½ å¿…é¡»æå‡ºè­¦å‘Šã€‚
5.  **æ•°æ®è¯šå®**: æ—¢ç„¶çŸ¥é“æ•°æ®æœ‰å±€é™æ€§ï¼Œåœ¨æ±‡æŠ¥ç»„å­¦ç»“æœæ—¶è¯·ä½¿ç”¨"åœ¨æˆ‘ä»¬æœ‰é™çš„æ•°æ®é›†ä¸­..."æˆ–"åˆæ­¥æ•°æ®è¡¨æ˜..."è¿™æ ·çš„æªè¾ã€‚
6.  **å›å¤è¯­è¨€**: å…¨éƒ¨ä½¿ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚
"""

    def call_deepseek(self) -> Optional[Dict]:
        """è°ƒç”¨ DeepSeek API"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
        }
        payload = {
            "model": MODEL_NAME,
            "messages": self.messages,
            "stream": False,
            "temperature": 0.0,
            "tools": self.loader.tools_schema if self.loader.tools_schema else None,
            "tool_choice": "auto" if self.loader.tools_schema else None
        }
        
        # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œç§»é™¤ç›¸å…³å­—æ®µ
        if not self.loader.tools_schema:
            payload.pop("tools", None)
            payload.pop("tool_choice", None)
            
        try:
            print("\nğŸ¤– [Agent] DeepSeek æ­£åœ¨æ€è€ƒ...", file=sys.stderr)
            response = requests.post(API_URL, headers=headers, json=payload, timeout=120)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ API é”™è¯¯: {e}", file=sys.stderr)
            return None

    def call_deepseek_stream(self) -> Generator[Dict, None, None]:
        """æµå¼è°ƒç”¨ DeepSeek API"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
        }
        payload = {
            "model": MODEL_NAME,
            "messages": self.messages,
            "stream": True,
            "temperature": 0.0,
            "tools": self.loader.tools_schema if self.loader.tools_schema else None,
            "tool_choice": "auto" if self.loader.tools_schema else None
        }
        
        if not self.loader.tools_schema:
            payload.pop("tools", None)
            payload.pop("tool_choice", None)
            
        try:
            response = requests.post(API_URL, headers=headers, json=payload, stream=True, timeout=120)
            response.raise_for_status()
            
            for line in response.iter_lines():
                if line:
                    line_text = line.decode('utf-8')
                    if line_text.startswith('data: '):
                        data_str = line_text[6:]
                        if data_str.strip() == '[DONE]':
                            break
                        try:
                            yield json.loads(data_str)
                        except json.JSONDecodeError:
                            continue
        except Exception as e:
            print(f"âŒ æµå¼ API é”™è¯¯: {e}", file=sys.stderr)
            yield {"error": str(e)}

    def run(self, user_query: str, max_steps: int = 25) -> str:
        """
        è¿è¡Œ Agentï¼ˆåŒæ­¥æ¨¡å¼ï¼‰
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            max_steps: æœ€å¤§æ¨ç†æ­¥æ•° (æ¢ç´¢ä»»åŠ¡é€šå¸¸éœ€è¦æ›´å¤šæ­¥éª¤)
            
        Returns:
            æœ€ç»ˆå›å¤å†…å®¹
        """
        print(f"\nğŸ‘¤ User: {user_query}")
        self.messages.append({"role": "user", "content": user_query})
        step_count = 0
        final_response = ""

        while step_count < max_steps:
            step_count += 1
            response_data = self.call_deepseek()
            if not response_data:
                break
            
            msg = response_data['choices'][0]['message']
            content = msg.get('content')
            tool_calls = msg.get('tool_calls')

            if content:
                print(f"\nğŸ§  [Thought]: {content}")
                final_response = content
                
            self.messages.append(msg)

            if tool_calls:
                print(f"ğŸ› ï¸  [Action]: éœ€è¦è°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·...")
                for tc in tool_calls:
                    func_name = tc['function']['name']
                    args_str = tc['function']['arguments']
                    tool_id = tc['id']
                    try:
                        args = json.loads(args_str)
                        print(f"   ğŸ“ è°ƒç”¨ {func_name}({args})")
                        result_str = self.loader.execute_tool(func_name, args)
                        preview = result_str[:200] + "..." if len(result_str) > 200 else result_str
                        print(f"   âœ… ç»“æœ: {preview}")
                        self.messages.append({
                            "role": "tool", 
                            "tool_call_id": tool_id, 
                            "name": func_name, 
                            "content": result_str
                        })
                    except Exception as e:
                        err = json.dumps({"status": "error", "message": str(e)})
                        self.messages.append({
                            "role": "tool", 
                            "tool_call_id": tool_id, 
                            "name": func_name, 
                            "content": err
                        })
                continue
            else:
                print(f"\nğŸ‰ [Done]: åˆ†æå®Œæˆ!")
                break
                
        return final_response

    def run_stream(self, user_query: str, max_steps: int = 25) -> Generator[Dict[str, Any], None, None]:
        """
        è¿è¡Œ Agentï¼ˆæµå¼æ¨¡å¼ï¼‰
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            max_steps: æœ€å¤§æ¨ç†æ­¥æ•° (æ¢ç´¢ä»»åŠ¡é€šå¸¸éœ€è¦æ›´å¤šæ­¥éª¤)
            
        Yields:
            æµå¼äº‹ä»¶å­—å…¸
        """
        self.messages.append({"role": "user", "content": user_query})
        step_count = 0
        
        yield {
            "type": "start",
            "query": user_query,
            "timestamp": datetime.now().isoformat()
        }

        while step_count < max_steps:
            step_count += 1
            
            yield {
                "type": "thinking",
                "step": step_count,
                "timestamp": datetime.now().isoformat()
            }
            
            response_data = self.call_deepseek()
            if not response_data:
                yield {
                    "type": "error",
                    "message": "API è°ƒç”¨å¤±è´¥",
                    "timestamp": datetime.now().isoformat()
                }
                break
            
            msg = response_data['choices'][0]['message']
            content = msg.get('content')
            tool_calls = msg.get('tool_calls')
            
            self.messages.append(msg)

            if content:
                yield {
                    "type": "thought",
                    "content": content,
                    "step": step_count,
                    "timestamp": datetime.now().isoformat()
                }

            if tool_calls:
                for tc in tool_calls:
                    func_name = tc['function']['name']
                    args_str = tc['function']['arguments']
                    tool_id = tc['id']
                    
                    yield {
                        "type": "tool_call",
                        "tool": func_name,
                        "arguments": args_str,
                        "step": step_count,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    try:
                        args = json.loads(args_str)
                        result_str = self.loader.execute_tool(func_name, args)
                        
                        yield {
                            "type": "tool_result",
                            "tool": func_name,
                            "result": result_str,  # è¿”å›å®Œæ•´ç»“æœï¼Œå‰ç«¯éœ€è¦è§£æè¯¦ç»†ä¿¡æ¯
                            "step": step_count,
                            "timestamp": datetime.now().isoformat()
                        }
                        
                        self.messages.append({
                            "role": "tool",
                            "tool_call_id": tool_id,
                            "name": func_name,
                            "content": result_str
                        })
                    except Exception as e:
                        err = json.dumps({"status": "error", "message": str(e)})
                        yield {
                            "type": "tool_error",
                            "tool": func_name,
                            "error": str(e),
                            "step": step_count,
                            "timestamp": datetime.now().isoformat()
                        }
                        self.messages.append({
                            "role": "tool",
                            "tool_call_id": tool_id,
                            "name": func_name,
                            "content": err
                        })
                continue
            else:
                yield {
                    "type": "complete",
                    "final_answer": content,
                    "total_steps": step_count,
                    "timestamp": datetime.now().isoformat()
                }
                break

    def get_available_tools(self) -> list:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return self.loader.get_tools_description()


if __name__ == "__main__":
    agent = DrKGCAgent()
    print(f"âœ… å·¥å…·ç®±å·²å°±ç»ª: {list(agent.loader.tool_configs.keys())}")
    
    while True:
        try:
            query = input("\nè¯·è¾“å…¥æ‚¨çš„åˆ†æéœ€æ±‚ (è¾“å…¥ 'exit' é€€å‡º): ")
            if query.strip().lower() == 'exit': break
            if not query.strip(): continue
            agent.run(query)
        except KeyboardInterrupt: break
